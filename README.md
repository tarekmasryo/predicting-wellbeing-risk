# ğŸŒŒ Digital Habits & Mental Health â€” Wellbeing Risk

Production-minded notebook for **binary wellbeing risk** (`high_risk_flag âˆˆ {0,1}`) derived from digital behavior signals.

---

## ğŸ¯ Goal
Predict a **calibrated wellbeing risk score** in `[0,1]` from daily digital patterns â€” screen time, unlocks, sleep, notifications, activity.

Focus:
- Stable CV, not leaderboard luck  
- Minimal, meaningful visuals  
- Zero leakage Â· Deployable artifacts  

---

## ğŸ§  End-to-End Pipeline
1. **Data Loading** â†’ clean read, column sanitization, dedup, schema snapshot  
2. **EDA (Focused)** â†’ leakage guard Â· top Spearman correlations Â· compact Plotly visuals  
3. **Feature Engineering** â†’ ratios & interactions Â· winsorized z-scores Â· log1p transforms  
4. **Models** â†’ Logistic Regression Â· Random Forest Â· XGBoost (auto GPU/CPU)  
5. **Calibration** â†’ isotonic reliability fit on the best model  
6. **Decisioning** â†’ min-cost threshold + capacity constraint (optional review rate)  
7. **Interpretability** â†’ AUC-based permutation importance (Kaggle-safe)  
8. **Export** â†’ calibrated model + schema + metadata + inference smoke test  

---

## ğŸ”¬ Features & Cross-Validation
**Key features (examples):**
- `screen_per_sleep_norm` = device_hours_per_day / sleep_hours  
- `unlocks_per_hour` = phone_unlocks / (device_hours_per_day + 0.1)  
- `social_ratio`, `work_ratio` from time splits  
- Winsorized z-scores for device_hours, sleep_hours, stress, anxiety, depression, happiness  
- log1p transforms for unlocks, social_media_minutes, work_minutes, notifications_per_day  


---

## ğŸ“ˆ Metrics & Visualization
- ROCâ€“AUC Â· Average Precision Â· Brier Score  
- Comparative ROC/PR curves (all models)  
- Reliability curve (calibrated best) Â· Lift curve  
- AUC-based permutation importance for interpretability  

---

## ğŸ§® Cost-Aware Decisioning
Threshold grid `t âˆˆ [0,1]` using:
```
total_cost = FP*C_fp + FN*C_fn - TP*benefit
```
- Report **min-cost** and **best-F1** thresholds  
- Optional **capacity constraint** â†’ choose lowest-cost threshold under review limit  

---

## ğŸ“‚ Outputs
All reproducible artifacts stored under `artifacts/`:

```
eda/        â†’ schema_overview.csv, engineered_corr.csv
metrics/    â†’ leaderboard_metrics.csv, permutation_importance_auc.csv
decision/   â†’ decision_cost_curve.csv, thresholds_summary.csv
models/     â†’ best_calibrated.joblib, feature_schema.json, model_info.json
inference/  â†’ smoke_test_report.json
```

---

## âš¡ Quick Start
```bash
pip install -r requirements.txt

```
Plotly renderer:
```python
import plotly.io as pio
pio.renderers.default = "notebook_connected"  # auto PNG fallback (kaleido)
```

---

## ğŸ—‚ï¸ Dataset
- **Target:** `high_risk_flag` (0/1)  
  If categorical â†’ `TARGET_MAP = {"Low":0, "High":1}`  
- **Default path:** `/kaggle/input/digital-health-and-mental-wellness/Data.csv`

---

## ğŸ“ Repo layout

```text
.
â”œâ”€â”€ predicting-wellbeing-risk.ipynb
â”œâ”€â”€ data/
â”‚   â””â”€â”€ raw/               # put Data.csv here for local runs
â”œâ”€â”€ artifacts/             # exported tables / metrics / model files
â”œâ”€â”€ repo_utils/
â”‚   â””â”€â”€ pathing.py         # local + Kaggle path helpers
â”œâ”€â”€ CASE_STUDY.md
â”œâ”€â”€ requirements.txt
â””â”€â”€ .gitignore
```

---

## ğŸ§­ Data loading (local + Kaggle)

**Local (recommended):**
- Put `Data.csv` under `data/raw/`

**Kaggle:**
- Falls back to `/kaggle/input/digital-health-and-mental-wellness/Data.csv`

**Optional override:**
- Set `DATA_PATH` to a full file path (local runs).

---

## ğŸ§¾ Case Study
See **CASE_STUDY.md** for the project story, decisions, and takeaways.
